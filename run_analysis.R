##  I wrote this code as a Course Project for Getting and Cleaning Data, by JHU on Coursera.
##  This code consists on downloading a dataset generated by the accelerometers 
##  installed on Samsung S smartphone, cleaning and manipulating the data to make it tidy.

##  A full description is available at the site where the data was obtained:
##  http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

##  Here are the data for the project:
##  https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip


rm(list = ls())

## ----------------------------------------------------------------------------------
## Download data set Files
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"

if(!file.exists ("Dataset.zip")) { 
  download.file(fileURL, destfile = "Dataset.zip", method = "curl")
  unzip("Dataset.zip", exdir = ".")
}

setwd("./UCI HAR Dataset")

## ----------------------------------------------------------------------------------
library(tidyverse)
## ----------------------------------------------------------------------------------
## Loading the data sets

## Activity Labels
activityFiles = "activity_labels.txt"

actLabels <- activityFiles %>% 
  read_delim(trim_ws = TRUE, col_names = FALSE, delim = " ") %>% 
  select(X2) 

## Subject IDs
subjectFiles <- c("./test/subject_test.txt", 
                  "./train/subject_train.txt")

subjectID <- subjectFiles %>% 
  lapply(function(x) { read_tsv(file = x, col_names = "subject_ID", col_types = "i")}) %>% 
  reduce(rbind)

## Training/Test labels (IDs)
trainingFiles <- c("./test/y_test.txt", 
                   "./train/y_train.txt")

trainingID <- trainingFiles %>% 
  lapply(function(x) { read_tsv(file = x, col_names = "Training")}) %>% 
  reduce(rbind) %>% 
  transmute(Activity = case_when(
    Training == 1 ~ actLabels$X2[1],
    Training == 2 ~ actLabels$X2[2],
    Training == 3 ~ actLabels$X2[3],
    Training == 4 ~ actLabels$X2[4],
    Training == 5 ~ actLabels$X2[5],
    Training == 6 ~ actLabels$X2[6]
    )
  )

## Features (these will be the columns names for the results obtained)
featuresFile = "features.txt"

featuresLabels <- featuresFile %>% 
  read_delim(trim_ws = TRUE, col_names = FALSE, delim = " ") %>% 
  select(X2) 

featuresIndex <- grep("mean\\(\\)|std\\(\\)", featuresLabels$X2)

featuresLabels <- featuresLabels[featuresIndex,]

## Training/Test sets
activitySetFiles <- c("./test/X_test.txt", 
                      "./train/X_train.txt")

activitySets <- activitySetFiles %>% 
  lapply(function(x) { read_delim(file = x, col_names = as.character(unlist(featuresLabels)), delim = " ", trim_ws = TRUE)}) %>% 
  reduce(rbind)

activitySets <- activitySets[,featuresIndex]

names(activitySets) <- gsub("^t", "time", names(activitySets))
names(activitySets) <- gsub("^f", "frequency", names(activitySets))
names(activitySets) <- gsub("Acc", "Accelerometer", names(activitySets))
names(activitySets) <- gsub("Gyro", "Gyroscope", names(activitySets))
names(activitySets) <- gsub("Mag", "Magnitude", names(activitySets))
names(activitySets) <- gsub("BodyBody", "Body", names(activitySets))
  
## Joining all data sets
dfList <- list(subjectID, trainingID, activitySets)
analysisDataSet <- Reduce(function(x,y){ cbind(x,y) }, dfList)

##  Grouping Variables and creating a summary dataset
analysisSummary <- analysisDataSet %>% group_by(subject_ID, Activity) 
analysisSummary <- analysisSummary %>% summarise_at(vars("timeBodyAccelerometer-mean()-X":"frequencyBodyGyroscopeJerkMagnitude-std()"), mean, na.rm = TRUE)

##  Saving external tables
if(!file.exists ("../Analysis")) { dir.create ("../Analysis") }
write.table(analysisSummary, file = "../Analysis/analysis_summaryTable.txt", row.names = FALSE)
write.table(analysisDataSet, file = "../Analysis/analysis_DataSet.txt", row.names = FALSE)
